# ä¸Šä¸‹æ–‡æ³¨å…¥æœåŠ¡ä½¿ç”¨æŒ‡å—

## æ¦‚è¿°

`ContextInjectionService` æ˜¯ä¸€ä¸ªç”¨äºå°†æ£€ç´¢åˆ°çš„æ–‡æ¡£å†…å®¹æ³¨å…¥åˆ°æç¤ºè¯ä¸­çš„æœåŠ¡ï¼Œæ”¯æŒå¼•ç”¨æº¯æºã€ä¸Šä¸‹æ–‡çª—å£ç®¡ç†ç­‰é«˜çº§åŠŸèƒ½ã€‚

## åŠŸèƒ½ç‰¹æ€§

- âœ… ä¸Šä¸‹æ–‡æ³¨å…¥åˆ°æç¤ºè¯
- âœ… æ™ºèƒ½æ–‡æ¡£é€‰æ‹©ï¼ˆæŒ‰ç›¸å…³æ€§æ’åºã€é•¿åº¦æ§åˆ¶ã€æ•°é‡é™åˆ¶ï¼‰
- âœ… å¼•ç”¨æ ‡æ³¨åŠŸèƒ½
- âœ… ä¸Šä¸‹æ–‡æ ¼å¼åŒ–
- âœ… å¼•ç”¨æº¯æºï¼ˆä»æ¨¡å‹å“åº”ä¸­æå–å¼•ç”¨ï¼‰
- âœ… ä¸Šä¸‹æ–‡çª—å£ç®¡ç†ï¼ˆmax_context_lengthã€max_documentsï¼‰
- âœ… ä¸Šä¸‹æ–‡éªŒè¯å’Œæˆªæ–­
- âœ… ä¸Šä¸‹æ–‡ç»Ÿè®¡ä¿¡æ¯

## åŸºæœ¬ä½¿ç”¨

### 1. åˆ›å»ºæœåŠ¡å®ä¾‹

```python
from app.services.context_injection_service import ContextInjectionService, create_context_injection_service

# æ–¹å¼1ï¼šç›´æ¥åˆ›å»º
service = ContextInjectionService(
    max_context_length=4000,  # æœ€å¤§ä¸Šä¸‹æ–‡é•¿åº¦
    max_documents=10,          # æœ€å¤§æ–‡æ¡£æ•°é‡
    citation_format="[{index}]" # å¼•ç”¨æ ¼å¼
)

# æ–¹å¼2ï¼šä½¿ç”¨å·¥å‚å‡½æ•°åˆ›å»º
service = create_context_injection_service(
    max_context_length=4000,
    max_documents=10
)
```

### 2. æ³¨å…¥ä¸Šä¸‹æ–‡åˆ°æç¤ºè¯

```python
from app.services.knowledge_base_service import KnowledgeBaseService
from app.services.hybrid_retriever import HybridRetriever

# 1. åˆå§‹åŒ–æœåŠ¡
kb_service = KnowledgeBaseService(db)
hybrid_retriever = HybridRetriever(kb_service, bm25_retriever)
context_service = ContextInjectionService(max_context_length=4000, max_documents=5)

# 2. æ£€ç´¢ç›¸å…³æ–‡æ¡£
query = "å¦‚ä½•è®¾è®¡æµ‹è¯•ç”¨ä¾‹çš„è¾¹ç•Œå€¼ï¼Ÿ"
retrieved_docs = hybrid_retriever.search(
    query=query,
    top_k=10,
    method="weighted"
)

# 3. å®šä¹‰æç¤ºè¯æ¨¡æ¿
prompt_template = """
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æµ‹è¯•è®¾è®¡åŠ©æ‰‹ã€‚è¯·æ ¹æ®ä»¥ä¸‹å‚è€ƒæ–‡æ¡£å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚

{{context}}

é—®é¢˜ï¼š{{query}}

è¯·ç»™å‡ºè¯¦ç»†çš„ç­”æ¡ˆï¼Œå¹¶åœ¨å›ç­”ä¸­å¼•ç”¨ç›¸å…³æ–‡æ¡£ã€‚
"""

# 4. æ³¨å…¥ä¸Šä¸‹æ–‡
result = context_service.inject_context(
    query=query,
    retrieved_docs=retrieved_docs,
    prompt_template=prompt_template,
    include_citations=True
)

# 5. è·å–ç»“æœ
final_prompt = result["prompt"]
context = result["context"]
citations = result["citations"]
used_docs = result["used_docs"]

print("æœ€ç»ˆæç¤ºè¯ï¼š")
print(final_prompt)
```

### 3. ä»æ¨¡å‹å“åº”ä¸­æå–å¼•ç”¨

```python
# å‡è®¾æ¨¡å‹ç”Ÿæˆçš„å“åº”
model_response = """
æ ¹æ®[1]è¾¹ç•Œå€¼æµ‹è¯•è§„èŒƒï¼Œè¾¹ç•Œå€¼æµ‹è¯•åº”è¯¥åŒ…æ‹¬ä»¥ä¸‹åœºæ™¯ï¼š
- æ­£å¸¸è¾¹ç•Œå€¼
- è¾¹ç•Œå€¼+1
- è¾¹ç•Œå€¼-1

åŒæ—¶ï¼Œå‚è€ƒ[2]æµ‹è¯•è®¾è®¡æ–¹æ³•ï¼Œå»ºè®®ä½¿ç”¨ç­‰ä»·ç±»åˆ’åˆ†æ³•è¾…åŠ©æµ‹è¯•è®¾è®¡ã€‚
"""

# æå–å¼•ç”¨
citations = context_service.extract_citations(
    response=model_response,
    documents=used_docs
)

# æ ¼å¼åŒ–å¼•ç”¨åˆ—è¡¨
citation_text = context_service.format_citations(citations)
print(citation_text)

# è¾“å‡ºç¤ºä¾‹ï¼š
# å¼•ç”¨æ¥æº:
# ================================================================================
# 
# [1] è¾¹ç•Œå€¼æµ‹è¯•è§„èŒƒ
#   ç±»å‹: è§„èŒƒ
#   ç›¸ä¼¼åº¦: 0.9523
#   å†…å®¹: è¾¹ç•Œå€¼æµ‹è¯•åº”è¯¥åŒ…æ‹¬æ­£å¸¸è¾¹ç•Œå€¼ã€è¾¹ç•Œå€¼+1ã€è¾¹ç•Œå€¼-1...
# 
# [2] æµ‹è¯•è®¾è®¡æ–¹æ³•
#   ç±»å‹: ä¸šåŠ¡è§„åˆ™
#   ç›¸ä¼¼åº¦: 0.8845
#   å†…å®¹: å»ºè®®ä½¿ç”¨ç­‰ä»·ç±»åˆ’åˆ†æ³•è¾…åŠ©æµ‹è¯•è®¾è®¡...
```

## é«˜çº§åŠŸèƒ½

### 1. æ–‡æ¡£é€‰æ‹©ç­–ç•¥

æœåŠ¡ä¼šè‡ªåŠ¨æŒ‰ä»¥ä¸‹ä¼˜å…ˆçº§é€‰æ‹©æ–‡æ¡£ï¼š

1. æŒ‰ç›¸å…³æ€§åˆ†æ•°æ’åºï¼ˆrerank_score > score > similarityï¼‰
2. å—é™äºæ–‡æ¡£æ•°é‡ï¼ˆmax_documentsï¼‰
3. å—é™äºä¸Šä¸‹æ–‡é•¿åº¦ï¼ˆmax_context_lengthï¼‰

```python
# è°ƒæ•´å‚æ•°ä»¥è·å¾—æ›´å¥½çš„ç»“æœ
service = ContextInjectionService(
    max_context_length=8000,  # å¢åŠ ä¸Šä¸‹æ–‡é•¿åº¦
    max_documents=15,          # å¢åŠ æ–‡æ¡£æ•°é‡
    citation_format="[ref_{index}]"  # è‡ªå®šä¹‰å¼•ç”¨æ ¼å¼
)

# é€‰æ‹©æ–‡æ¡£
selected_docs = service.select_documents(
    retrieved_docs=retrieved_docs,
    max_length=8000,
    max_docs=15
)
```

### 2. ä¸Šä¸‹æ–‡éªŒè¯

```python
# éªŒè¯ä¸Šä¸‹æ–‡é•¿åº¦æ˜¯å¦åœ¨é™åˆ¶èŒƒå›´å†…
context = "å¾ˆé•¿çš„ä¸Šä¸‹æ–‡å†…å®¹..."
validation = service.validate_context_length(context)

if not validation["valid"]:
    print(f"ä¸Šä¸‹æ–‡è¶…å‡ºé™åˆ¶ {validation['exceeded']} å­—ç¬¦")
    print(f"å½“å‰é•¿åº¦: {validation['length']}")
    print(f"æœ€å¤§é•¿åº¦: {validation['max_length']}")
    print(f"ä½¿ç”¨ç‡: {validation['percentage']:.1f}%")
```

### 3. ä¸Šä¸‹æ–‡æˆªæ–­

```python
# æˆªæ–­ä¸Šä¸‹æ–‡ä»¥é€‚åº”é•¿åº¦é™åˆ¶
context = "å¾ˆé•¿çš„ä¸Šä¸‹æ–‡å†…å®¹..."
truncated = service.truncate_context_to_fit(
    context=context,
    max_length=4000,
    add_truncation_marker=True
)

print(f"æˆªæ–­åé•¿åº¦: {len(truncated)}")
```

### 4. è·å–ä¸Šä¸‹æ–‡ç»Ÿè®¡ä¿¡æ¯

```python
# è·å–ç»Ÿè®¡ä¿¡æ¯
stats = service.get_context_stats(context)
print(f"å­—ç¬¦æ•°: {stats['char_count']}")
print(f"è¯æ•°: {stats['word_count']}")
print(f"è¡Œæ•°: {stats['line_count']}")
```

## å®Œæ•´ç¤ºä¾‹ï¼šä¸é‡æ’åºæœåŠ¡é›†æˆ

```python
from app.services.knowledge_base_service import KnowledgeBaseService
from app.services.bm25_retriever import BM25Retriever
from app.services.hybrid_retriever import HybridRetriever
from app.services.reranker_service import RerankerService
from app.services.context_injection_service import ContextInjectionService

# åˆå§‹åŒ–æ‰€æœ‰æœåŠ¡
kb_service = KnowledgeBaseService(db)
bm25_retriever = BM25Retriever(k1=1.5, b=0.75)
hybrid_retriever = HybridRetriever(
    knowledge_base_service=kb_service,
    bm25_retriever=bm25_retriever,
    vector_weight=0.7,
    bm25_weight=0.3
)
reranker = RerankerService(model_name="BAAI/bge-reranker-large")
context_service = ContextInjectionService(
    max_context_length=4000,
    max_documents=5
)

# å®Œæ•´çš„RAGæµç¨‹
query = "å¦‚ä½•è®¾è®¡æµ‹è¯•ç”¨ä¾‹ï¼Ÿ"

# 1. æ··åˆæ£€ç´¢
retrieved_docs = hybrid_retriever.search(query=query, top_k=20)

# 2. é‡æ’åº
reranked_docs = reranker.rerank(query=query, documents=retrieved_docs, top_k=10)

# 3. ä¸Šä¸‹æ–‡æ³¨å…¥
prompt_template = """
ä½ æ˜¯æµ‹è¯•è®¾è®¡åŠ©æ‰‹ï¼Œè¯·æ ¹æ®ä»¥ä¸‹å‚è€ƒæ–‡æ¡£å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚

{{context}}

é—®é¢˜ï¼š{{query}}

è¯·ç»™å‡ºè¯¦ç»†çš„ç­”æ¡ˆï¼Œå¹¶åœ¨å›ç­”ä¸­å¼•ç”¨ç›¸å…³æ–‡æ¡£ã€‚
"""

injection_result = context_service.inject_context(
    query=query,
    retrieved_docs=reranked_docs,
    prompt_template=prompt_template,
    include_citations=True
)

# 4. ä½¿ç”¨æœ€ç»ˆæç¤ºè¯è°ƒç”¨å¤§æ¨¡å‹
final_prompt = injection_result["prompt"]
# è°ƒç”¨LLM...
# response = llm.generate(final_prompt)

# 5. ä»å“åº”ä¸­æå–å¼•ç”¨
# citations = context_service.extract_citations(response, injection_result["used_docs"])
# citation_text = context_service.format_citations(citations)
```

## è‡ªå®šä¹‰é…ç½®

### è‡ªå®šä¹‰å¼•ç”¨æ ¼å¼

```python
# ä½¿ç”¨ä¸åŒçš„å¼•ç”¨æ ¼å¼
service1 = ContextInjectionService(citation_format="[{index}]")  # [1], [2], [3]
service2 = ContextInjectionService(citation_format="(ref_{index})")  # (ref_1), (ref_2), (ref_3)
service3 = ContextInjectionService(citation_format="ğŸ“„{index}")  # ğŸ“„1, ğŸ“„2, ğŸ“„3
```

### è‡ªå®šä¹‰ä¸Šä¸‹æ–‡å ä½ç¬¦

```python
# ä½¿ç”¨ä¸åŒçš„å ä½ç¬¦
result = context_service.inject_context(
    query=query,
    retrieved_docs=retrieved_docs,
    prompt_template=prompt_template,
    include_citations=True,
    context_placeholder="{{knowledge_base}}"  # ä½¿ç”¨è‡ªå®šä¹‰å ä½ç¬¦
)
```

## æœ€ä½³å®è·µ

### 1. å‚æ•°è°ƒä¼˜

- **max_context_length**: æ ¹æ®æ¨¡å‹ä¸Šä¸‹æ–‡çª—å£è®¾ç½®
  - å°æ¨¡å‹ï¼ˆ7Bï¼‰ï¼š2000-4000
  - ä¸­ç­‰æ¨¡å‹ï¼ˆ13Bï¼‰ï¼š4000-8000
  - å¤§æ¨¡å‹ï¼ˆ70B+ï¼‰ï¼š8000-16000

- **max_documents**: é€šå¸¸è®¾ç½®5-10ä¸ªæ–‡æ¡£
  - å¤ªå°‘ï¼šä¿¡æ¯ä¸è¶³
  - å¤ªå¤šï¼šä¸Šä¸‹æ–‡å†—ä½™ï¼Œå¢åŠ æˆæœ¬

### 2. å¼•ç”¨æ ‡æ³¨

```python
# å§‹ç»ˆå¯ç”¨å¼•ç”¨æ ‡æ³¨ï¼Œä¾¿äºæº¯æº
result = context_service.inject_context(
    query=query,
    retrieved_docs=retrieved_docs,
    prompt_template=prompt_template,
    include_citations=True  # å»ºè®®å§‹ç»ˆä¸ºTrue
)

# åœ¨æç¤ºè¯ä¸­å¼•å¯¼æ¨¡å‹ä½¿ç”¨å¼•ç”¨
prompt_template = """
...{{context}}...

è¯·å¼•ç”¨ç›¸å…³æ–‡æ¡£ï¼Œä½¿ç”¨[1]ã€[2]ç­‰æ ¼å¼æ ‡æ³¨ã€‚
"""
```

### 3. é”™è¯¯å¤„ç†

```python
try:
    result = context_service.inject_context(
        query=query,
        retrieved_docs=retrieved_docs,
        prompt_template=prompt_template
    )
    
    # éªŒè¯ç»“æœ
    if not result["used_docs"]:
        print("è­¦å‘Šï¼šæ²¡æœ‰é€‰æ‹©ä»»ä½•æ–‡æ¡£")
        return "æŠ±æ­‰ï¼Œæ²¡æœ‰æ‰¾åˆ°ç›¸å…³ä¿¡æ¯"
    
    # æ£€æŸ¥ä¸Šä¸‹æ–‡é•¿åº¦
    validation = context_service.validate_context_length(result["context"])
    if not validation["valid"]:
        print(f"è­¦å‘Šï¼šä¸Šä¸‹æ–‡è¶…å‡ºé™åˆ¶ {validation['exceeded']} å­—ç¬¦")
    
except Exception as e:
    print(f"ä¸Šä¸‹æ–‡æ³¨å…¥å¤±è´¥: {str(e)}")
    return None
```

## æ€§èƒ½ä¼˜åŒ–

### 1. æ‰¹é‡å¤„ç†

```python
# æ‰¹é‡å¤„ç†å¤šä¸ªæŸ¥è¯¢
queries = ["å¦‚ä½•è®¾è®¡æµ‹è¯•ç”¨ä¾‹ï¼Ÿ", "è¾¹ç•Œå€¼æµ‹è¯•åŒ…æ‹¬å“ªäº›åœºæ™¯ï¼Ÿ"]
for query in queries:
    result = context_service.inject_context(
        query=query,
        retrieved_docs=retrieved_docs,
        prompt_template=prompt_template
    )
    # å¤„ç†ç»“æœ...
```

### 2. ç¼“å­˜ä¸Šä¸‹æ–‡

```python
from functools import lru_cache

@lru_cache(maxsize=100)
def get_cached_context(query: str):
    retrieved_docs = hybrid_retriever.search(query=query, top_k=10)
    result = context_service.inject_context(
        query=query,
        retrieved_docs=retrieved_docs,
        prompt_template=prompt_template
    )
    return result
```

## å¸¸è§é—®é¢˜

### Q1: å¦‚ä½•è°ƒæ•´ä¸Šä¸‹æ–‡çª—å£å¤§å°ï¼Ÿ

A: æ ¹æ®æ¨¡å‹çš„ä¸Šä¸‹æ–‡çª—å£å¤§å°è°ƒæ•´ï¼š
```python
# GPT-3.5: 4096 tokens
service = ContextInjectionService(max_context_length=4000)

# GPT-4: 8192 tokens
service = ContextInjectionService(max_context_length=8000)

# Claude: 100000 tokens
service = ContextInjectionService(max_context_length=50000)
```

### Q2: å¦‚ä½•å¤„ç†è¶…é•¿çš„ä¸Šä¸‹æ–‡ï¼Ÿ

A: ä½¿ç”¨æˆªæ–­åŠŸèƒ½ï¼š
```python
# éªŒè¯å¹¶æˆªæ–­
validation = service.validate_context_length(context)
if not validation["valid"]:
    context = service.truncate_context_to_fit(
        context=context,
        max_length=service.max_context_length
    )
```

### Q3: å¦‚ä½•æé«˜å¼•ç”¨å‡†ç¡®æ€§ï¼Ÿ

A: ä¼˜åŒ–æ£€ç´¢å’Œé‡æ’åºï¼š
```python
# 1. ä½¿ç”¨æ··åˆæ£€ç´¢
retrieved_docs = hybrid_retriever.search(
    query=query,
    top_k=20,  # æ£€ç´¢æ›´å¤šæ–‡æ¡£
    method="weighted"
)

# 2. ä½¿ç”¨é‡æ’åº
reranked_docs = reranker.rerank(
    query=query,
    documents=retrieved_docs,
    top_k=10  # ä¿ç•™æœ€ç›¸å…³çš„10ä¸ª
)

# 3. ä½¿ç”¨é‡æ’åºåçš„ç»“æœ
result = context_service.inject_context(
    query=query,
    retrieved_docs=reranked_docs,  # ä½¿ç”¨é‡æ’åºåçš„æ–‡æ¡£
    prompt_template=prompt_template
)
```

## æ€»ç»“

`ContextInjectionService` æä¾›äº†å®Œæ•´çš„ä¸Šä¸‹æ–‡ç®¡ç†å’Œå¼•ç”¨æº¯æºåŠŸèƒ½ï¼Œä¸æ£€ç´¢å’Œé‡æ’åºæœåŠ¡é…åˆä½¿ç”¨ï¼Œå¯ä»¥æ„å»ºé«˜è´¨é‡çš„RAGç³»ç»Ÿã€‚

æ ¸å¿ƒæ–¹æ³•ï¼š
- `inject_context()`: æ³¨å…¥ä¸Šä¸‹æ–‡åˆ°æç¤ºè¯
- `select_documents()`: æ™ºèƒ½é€‰æ‹©æ–‡æ¡£
- `extract_citations()`: ä»å“åº”ä¸­æå–å¼•ç”¨
- `format_citations()`: æ ¼å¼åŒ–å¼•ç”¨åˆ—è¡¨
- `validate_context_length()`: éªŒè¯ä¸Šä¸‹æ–‡é•¿åº¦
- `truncate_context_to_fit()`: æˆªæ–­ä¸Šä¸‹æ–‡
- `get_context_stats()`: è·å–ç»Ÿè®¡ä¿¡æ¯

